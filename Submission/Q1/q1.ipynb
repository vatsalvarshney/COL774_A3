{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from tqdm import tqdm\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, PredefinedSplit\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = None \n",
    "\n",
    "def get_np_array_ordinal(file_name):\n",
    "    global label_encoder\n",
    "    data = pd.read_csv(file_name)\n",
    "    \n",
    "    need_label_encoding = ['team','host','opp','month', 'day_match']\n",
    "    if(label_encoder is None):\n",
    "        label_encoder = OrdinalEncoder()\n",
    "        # label_encoder = OrdinalEncoder(sparse_output = False)\n",
    "        label_encoder.fit(data[need_label_encoding])\n",
    "    data_1 = pd.DataFrame(label_encoder.transform(data[need_label_encoding]), columns = label_encoder.get_feature_names_out())\n",
    "    \n",
    "    #merge the two dataframes\n",
    "    dont_need_label_encoding =  [\"year\",\"toss\",\"bat_first\",\"format\" ,\"fow\",\"score\" ,\"rpo\" ,\"result\"]\n",
    "    data_2 = data[dont_need_label_encoding]\n",
    "    final_data = pd.concat([data_1, data_2], axis=1)\n",
    "    \n",
    "    X = final_data.iloc[:,:-1]\n",
    "    y = final_data.iloc[:,-1:]\n",
    "    return X.to_numpy(), y.to_numpy()\n",
    "\n",
    "def get_np_array_one_hot(file_name):\n",
    "    global label_encoder\n",
    "    data = pd.read_csv(file_name)\n",
    "    \n",
    "    need_label_encoding = ['team','host','opp','month', 'day_match']\n",
    "    if(label_encoder is None):\n",
    "        label_encoder = OneHotEncoder(sparse_output = False)\n",
    "        label_encoder.fit(data[need_label_encoding])\n",
    "    data_1 = pd.DataFrame(label_encoder.transform(data[need_label_encoding]), columns = label_encoder.get_feature_names_out())\n",
    "    \n",
    "    #merge the two dataframes\n",
    "    dont_need_label_encoding =  [\"year\",\"toss\",\"bat_first\",\"format\" ,\"fow\",\"score\" ,\"rpo\" ,\"result\"]\n",
    "    data_2 = data[dont_need_label_encoding]\n",
    "    final_data = pd.concat([data_1, data_2], axis=1)\n",
    "    \n",
    "    X = final_data.iloc[:,:-1]\n",
    "    y = final_data.iloc[:,-1:]\n",
    "    return X.to_numpy(), y.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DTNode:\n",
    "    # Decision Tree Node\n",
    "\n",
    "    def __init__(self, depth):\n",
    "        self.depth = depth\n",
    "        self.value = 0\n",
    "        self.is_leaf = False\n",
    "        self.column = None\n",
    "        self.children = {}\n",
    "        self.type = None\n",
    "        self.median = None\n",
    "\n",
    "\n",
    "    def get_children(self, X):\n",
    "        '''\n",
    "        Args:\n",
    "            X: A single example np array [num_features]\n",
    "        Returns:\n",
    "            child: A DTNode\n",
    "        '''\n",
    "        if self.is_leaf:\n",
    "            return None\n",
    "        if self.type == 'cat':\n",
    "            if X[self.column] in self.children:\n",
    "                return self.children[X[self.column]]\n",
    "            else:\n",
    "                return None\n",
    "        if self.type == 'cont':\n",
    "            if X[self.column] <= self.median:\n",
    "                return self.children[0]\n",
    "            else:\n",
    "                return self.children[1]\n",
    "        return None\n",
    "\n",
    "\n",
    "class DTTree:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.root = None\n",
    "\n",
    "\n",
    "    def fit(self, X, y, types, max_depth = 10):\n",
    "        '''\n",
    "        Makes decision tree\n",
    "\n",
    "        Args:\n",
    "            X: numpy array of data [num_samples, num_features]\n",
    "            y: numpy array of classes [num_samples, 1]\n",
    "            types: list of [num_features] with types as: cat, cont\n",
    "                eg: if num_features = 4, and last 2 features are continious then\n",
    "                    types = ['cat','cat','cont','cont']\n",
    "            max_depth: maximum depth of tree\n",
    "        Returns:\n",
    "            None\n",
    "        '''\n",
    "        self.root = DTNode(0)\n",
    "        self.root = self.__fit(self.root, X, y, types, max_depth)\n",
    "        return None\n",
    "\n",
    "\n",
    "    def __fit(self, node: DTNode, X: np.ndarray, y: np.ndarray, types: list, max_depth: int) -> DTNode:\n",
    "        '''\n",
    "        Recursively makes decision tree\n",
    "\n",
    "        Args:\n",
    "            node: DTNode\n",
    "            X: numpy array of data [num_samples, num_features]\n",
    "            y: numpy array of classes [num_samples, 1]\n",
    "            types: list of [num_features] with types as: cat, cont\n",
    "                eg: if num_features = 4, and last 2 features are continious then\n",
    "                    types = ['cat','cat','cont','cont']\n",
    "            max_depth: maximum depth of tree\n",
    "        Returns:\n",
    "            node: DTNode\n",
    "        '''\n",
    "\n",
    "        node.value = stats.mode(y)[0][0]\n",
    "\n",
    "        if node.depth == max_depth or np.unique(y).size == 1:\n",
    "            node.is_leaf = True\n",
    "            return node\n",
    "        \n",
    "        mutual_info = [self.__mutual_info(X[:,i], y[:,0], types[i]) for i in range(X.shape[1])]\n",
    "        node.column = np.argmax(mutual_info)\n",
    "        node.type = types[node.column]\n",
    "        x_split = X[:,node.column]\n",
    "\n",
    "        node.children = {}\n",
    "        if node.type == 'cat':\n",
    "            for i in np.unique(x_split):\n",
    "                idx = x_split == i\n",
    "                node.children[i] = DTNode(node.depth+1)\n",
    "                node.children[i] = self.__fit(node.children[i], X[idx], y[idx], types, max_depth)\n",
    "        else:\n",
    "            node.median = np.median(x_split)\n",
    "            less = x_split <= node.median\n",
    "            node.children[0] = DTNode(node.depth+1)\n",
    "            node.children[0] = self.__fit(node.children[0], X[less], y[less], types, max_depth)\n",
    "            node.children[1] = DTNode(node.depth+1)\n",
    "            node.children[1] = self.__fit(node.children[1], X[~less], y[~less], types, max_depth)\n",
    "\n",
    "        return node\n",
    "\n",
    "\n",
    "    def __mutual_info(self, x: np.ndarray, y: np.ndarray, type='cat'):\n",
    "        '''\n",
    "        Calculates mutual information between x and y\n",
    "\n",
    "        Args:\n",
    "            x: numpy array of data [num_samples]\n",
    "            y: numpy array of classes [num_samples]\n",
    "            type: type of attribute x, 'cat' (categorical) or 'cont' (continuous)\n",
    "        Returns:\n",
    "            mutual_info: float\n",
    "        '''\n",
    "        splits = []\n",
    "        if type == 'cat':\n",
    "            splits = [x == i for i in np.unique(x)]\n",
    "        else:\n",
    "            less = x <= np.median(x)\n",
    "            splits = [less, ~less]\n",
    "        mutual_info = 0\n",
    "        for split in splits:\n",
    "            mutual_info += np.sum(split) / x.size * self.__entropy(y[split])\n",
    "        mutual_info = self.__entropy(y) - mutual_info\n",
    "        return mutual_info\n",
    "\n",
    "    \n",
    "    def __entropy(self, y: np.ndarray) -> float:\n",
    "        '''\n",
    "        Calculates entropy of y\n",
    "\n",
    "        Args:\n",
    "            y: numpy array of classes [num_samples]\n",
    "        Returns:\n",
    "            entropy: float\n",
    "        '''\n",
    "        entropy = 0\n",
    "        for i in np.unique(y):\n",
    "            p = np.sum(y == i) / y.size\n",
    "            entropy -= p * np.log2(p)\n",
    "        return entropy\n",
    "\n",
    "\n",
    "    def __call__(self, X):\n",
    "        '''\n",
    "        Predicted classes for X\n",
    "\n",
    "        Args:\n",
    "            X: numpy array of data [num_samples, num_features]\n",
    "        Returns:\n",
    "            y: [num_samples, 1] predicted classes\n",
    "        '''\n",
    "        y = np.zeros((X.shape[0], 1))\n",
    "        for i in range(X.shape[0]):\n",
    "            y[i] = self.__pred(self.root, X[i])\n",
    "        return y\n",
    "\n",
    "\n",
    "    def __pred(self, node: DTNode, X: np.ndarray):\n",
    "        '''\n",
    "        Predicted class for a single example X\n",
    "\n",
    "        Args:\n",
    "            node: DTNode\n",
    "            X: numpy array of data [num_features]\n",
    "        Returns:\n",
    "            y: float predicted class\n",
    "        '''\n",
    "        child = node.get_children(X)\n",
    "        if child is None:\n",
    "            return node.value\n",
    "        return self.__pred(child, X)\n",
    "\n",
    "\n",
    "    def accuracy(self, X: np.ndarray, y: np.ndarray):\n",
    "        '''\n",
    "        Calculates accuracy of the model on X and y\n",
    "\n",
    "        Args:\n",
    "            X: numpy array of data [num_samples, num_features]\n",
    "            y: numpy array of classes [num_samples, 1]\n",
    "        Returns:\n",
    "            accuracy: float between [0,1]\n",
    "        '''\n",
    "        return np.sum(self(X) == y) / y.size\n",
    "\n",
    "\n",
    "    def get_nodes(self) -> list[DTNode]:\n",
    "        '''\n",
    "        Returns all nodes of the tree\n",
    "\n",
    "        Args:\n",
    "            None\n",
    "        Returns:\n",
    "            nodes: list of DTNode\n",
    "        '''\n",
    "        nodes = []\n",
    "        self.__get_nodes(self.root, nodes)\n",
    "        return nodes\n",
    "\n",
    "    def __get_nodes(self, node: DTNode, nodes: list):\n",
    "        '''\n",
    "        Recursively gets all nodes of the tree\n",
    "\n",
    "        Args:\n",
    "            node: DTNode\n",
    "            nodes: list of DTNode\n",
    "        Returns:\n",
    "            None\n",
    "        '''\n",
    "        nodes.append(node)\n",
    "        if not node.is_leaf:\n",
    "            for child in node.children.values():\n",
    "                self.__get_nodes(child, nodes)\n",
    "    \n",
    "\n",
    "    def post_prune(self, X_train: np.ndarray, y_train:np.ndarray,\n",
    "                   X_val: np.ndarray, y_val: np.ndarray,\n",
    "                   X_test: np.ndarray, y_test: np.ndarray):\n",
    "        '''\n",
    "        Post prunes the tree\n",
    "\n",
    "        Args:\n",
    "            X_train: numpy array of data [num_samples, num_features]\n",
    "            y_train: numpy array of classes [num_samples, 1]\n",
    "            X_val: numpy array of data [num_samples, num_features]\n",
    "            y_val: numpy array of classes [num_samples, 1]\n",
    "            X_test: numpy array of data [num_samples, num_features]\n",
    "            y_test: numpy array of classes [num_samples, 1]\n",
    "        Returns:\n",
    "            num_nodes: numpy array of number of nodes [num_nodes]\n",
    "            train_accs: numpy array of accuracies [num_nodes + 1]\n",
    "            val_accs: numpy array of accuracies [num_nodes + 1]\n",
    "            test_accs: numpy array of accuracies [num_nodes + 1]\n",
    "        '''\n",
    "        \n",
    "        num_nodes = []\n",
    "        train_accs = []\n",
    "        val_accs = []\n",
    "        test_accs = []\n",
    "\n",
    "        while True:\n",
    "            nodes = self.get_nodes()\n",
    "            num_nodes.append(len(nodes))\n",
    "            acc = self.accuracy(X_val, y_val)\n",
    "            train_accs.append(self.accuracy(X_train, y_train))\n",
    "            val_accs.append(acc)\n",
    "            test_accs.append(self.accuracy(X_test, y_test))\n",
    "            max_acc = 0\n",
    "            max_node = None\n",
    "            for node in nodes:\n",
    "                if node.is_leaf:\n",
    "                    continue\n",
    "                node.is_leaf = True\n",
    "                acc_new = self.accuracy(X_val, y_val)\n",
    "                if acc_new > max_acc:\n",
    "                    max_acc = acc_new\n",
    "                    max_node = node\n",
    "                node.is_leaf = False\n",
    "            if max_acc > acc:\n",
    "                max_node.is_leaf = True\n",
    "            else:\n",
    "                break\n",
    "        \n",
    "        return np.array(num_nodes), np.array(train_accs), np.array(val_accs), np.array(test_accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = get_np_array_ordinal('train.csv')\n",
    "X_test, y_test = get_np_array_ordinal('test.csv')\n",
    "types = ['cat','cat','cat','cat','cat','cont','cat','cat','cat','cont','cont','cont']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depths = [5, 10, 15, 20, 25]\n",
    "train_acc = []\n",
    "test_acc = []\n",
    "for depth in tqdm(depths):\n",
    "    tree = DTTree()\n",
    "    tree.fit(X_train, y_train, types, depth)\n",
    "    train_acc.append(100*tree.accuracy(X_train, y_train))\n",
    "    test_acc.append(100*tree.accuracy(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'Depth':depths, 'Train accuracy (%)':train_acc, 'Test accuracy (%)':test_acc}).round(4)\n",
    "display(df)\n",
    "only_win_acc = 100*np.sum(y_test == 1) / y_test.size\n",
    "only_lose_acc = 100*np.sum(y_test == 0) / y_test.size\n",
    "print(f'Only win accuracy: {only_win_acc:.4f} %')\n",
    "print(f'Only lose accuracy: {only_lose_acc:.4f} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(depths, train_acc, label = 'Train accuracy')\n",
    "plt.plot(depths, test_acc, label = 'Test accuracy')\n",
    "plt.scatter(depths, train_acc)\n",
    "plt.scatter(depths, test_acc)\n",
    "plt.xlabel('Maximum depth')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Q1(a): Accuracy vs Maximum depth (Ordinal Encoding)')\n",
    "plt.legend()\n",
    "plt.gca().xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "plt.savefig('plots/q1a.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = None\n",
    "X_train, y_train = get_np_array_one_hot('train.csv')\n",
    "X_test, y_test = get_np_array_one_hot('test.csv')\n",
    "X_val, y_val = get_np_array_one_hot('val.csv')\n",
    "types = ['cat','cat','cat','cat','cat','cont','cat','cat','cat','cont','cont','cont']\n",
    "while len(types) != X_train.shape[1]:\n",
    "    types = ['cat'] + types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depths = [15,25,29,35,45,60,75]\n",
    "trees = []\n",
    "train_acc = []\n",
    "test_acc = []\n",
    "for depth in tqdm(depths):\n",
    "    trees.append(DTTree())\n",
    "    trees[-1].fit(X_train, y_train, types, depth)\n",
    "    train_acc.append(100*trees[-1].accuracy(X_train, y_train))\n",
    "    test_acc.append(100*trees[-1].accuracy(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'Depth':depths, 'Train accuracy (%)':train_acc, 'Test accuracy (%)':test_acc}).round(4)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "plt.plot(depths, train_acc, label = 'Train accuracy')\n",
    "plt.plot(depths, test_acc, label = 'Test accuracy')\n",
    "plt.scatter(depths, train_acc)\n",
    "plt.scatter(depths, test_acc)\n",
    "plt.xlabel('Maximum depth')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Q1(b): Accuracy vs Maximum depth (One Hot Encoding)')\n",
    "plt.legend()\n",
    "plt.savefig('plots/q1b.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tree,dep in [(trees[0],15),(trees[1],25),(trees[3],35),(trees[4],45)]:\n",
    "    print(f'Pruning tree with max depth = {dep}... ', end='')\n",
    "    st = time()\n",
    "    num_nodes, train_acc, val_acc, test_acc = tree.post_prune(X_train, y_train, X_val, y_val, X_test, y_test)\n",
    "    print(f'Done in {time()-st:.2f} s')\n",
    "    plt.clf()\n",
    "    plt.plot(num_nodes, train_acc, label = 'Train')\n",
    "    plt.plot(num_nodes, val_acc, label = 'Validation')\n",
    "    plt.plot(num_nodes, test_acc, label = 'Test')\n",
    "    plt.scatter(num_nodes, train_acc, s=10)\n",
    "    plt.scatter(num_nodes, val_acc, s=10)\n",
    "    plt.scatter(num_nodes, test_acc, s=10)\n",
    "    plt.xlabel('Number of nodes')\n",
    "    plt.ylabel('Accuracy (%)')\n",
    "    plt.title(f'Q1(c): Accuracy vs Number of nodes (max depth = {dep})')\n",
    "    plt.legend()\n",
    "    plt.savefig(f'plots/q1c_{dep}.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = DecisionTreeClassifier(criterion = 'entropy')\n",
    "tree.fit(X_train, y_train)\n",
    "train_acc = 100*tree.score(X_train, y_train)\n",
    "test_acc = 100*tree.score(X_test, y_test)\n",
    "print(f'Train accuracy: {train_acc:.4f} %')\n",
    "print(f'Test accuracy: {test_acc:.4f} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depths = [15,25,35,45]\n",
    "train_acc = []\n",
    "val_acc = []\n",
    "test_acc = []\n",
    "for depth in depths:\n",
    "    tree = DecisionTreeClassifier(criterion = 'entropy', max_depth = depth)\n",
    "    tree.fit(X_train, y_train)\n",
    "    train_acc.append(100*tree.score(X_train, y_train))\n",
    "    val_acc.append(100*tree.score(X_val, y_val))\n",
    "    test_acc.append(100*tree.score(X_test, y_test))\n",
    "\n",
    "df = pd.DataFrame({'Depth':depths, 'Train accuracy (%)':train_acc, 'Validation accuracy (%)':val_acc, 'Test accuracy (%)':test_acc}).round(4)\n",
    "display(df)\n",
    "\n",
    "plt.clf()\n",
    "plt.plot(depths, train_acc, label = 'Train')\n",
    "plt.plot(depths, val_acc, label = 'Validation')\n",
    "plt.plot(depths, test_acc, label = 'Test')\n",
    "plt.scatter(depths, train_acc)\n",
    "plt.scatter(depths, val_acc)\n",
    "plt.scatter(depths, test_acc)\n",
    "plt.xlabel('Maximum depth')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Q1(d): Accuracy vs Maximum depth (Sklearn)')\n",
    "plt.legend()\n",
    "plt.savefig('plots/q1d_depth.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccp_alphas = [0.001, 0.01, 0.1, 0.2]\n",
    "train_acc = []\n",
    "val_acc = []\n",
    "test_acc = []\n",
    "\n",
    "for ccp_alpha in ccp_alphas:\n",
    "    tree = DecisionTreeClassifier(criterion = 'entropy', ccp_alpha = ccp_alpha)\n",
    "    tree.fit(X_train, y_train)\n",
    "    train_acc.append(100*tree.score(X_train, y_train))\n",
    "    val_acc.append(100*tree.score(X_val, y_val))\n",
    "    test_acc.append(100*tree.score(X_test, y_test))\n",
    "\n",
    "df = pd.DataFrame({'ccp_alpha':ccp_alphas, 'Train accuracy (%)':train_acc, 'Validation accuracy (%)':val_acc, 'Test accuracy (%)':test_acc}).round(4)\n",
    "display(df)\n",
    "\n",
    "plt.clf()\n",
    "plt.plot(ccp_alphas, train_acc, label = 'Train')\n",
    "plt.plot(ccp_alphas, val_acc, label = 'Validation')\n",
    "plt.plot(ccp_alphas, test_acc, label = 'Test')\n",
    "plt.scatter(ccp_alphas, train_acc)\n",
    "plt.scatter(ccp_alphas, val_acc)\n",
    "plt.scatter(ccp_alphas, test_acc)\n",
    "plt.xscale('log')\n",
    "plt.xlabel('ccp_alpha')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Q1(d): Accuracy vs ccp_alpha (Sklearn)')\n",
    "plt.legend()\n",
    "plt.savefig('plots/q1d_ccp.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [50, 150, 250, 350],\n",
    "    'max_features': [0.1, 0.3, 0.5, 0.7, 0.9],\n",
    "    'min_samples_split': [2, 4, 6, 8, 10]\n",
    "}\n",
    "\n",
    "X_cv = np.concatenate((X_train, X_val), axis=0)\n",
    "y_cv = np.concatenate((y_train, y_val), axis=0)\n",
    "test_fold = np.concatenate((np.zeros(X_train.shape[0]), np.ones(X_val.shape[0])), axis=0)\n",
    "ps = PredefinedSplit(test_fold-1)\n",
    "rf = RandomForestClassifier(oob_score = True, criterion='entropy')\n",
    "grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, cv = ps, n_jobs = -1, verbose=3)\n",
    "grid_search.fit(X_cv, y_cv.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Best parameters: {grid_search.best_params_}')\n",
    "print(f'Best training accuracy: {100*grid_search.best_estimator_.score(X_train, y_train):.4f} %')\n",
    "print(f'Best out-of-bag accuracy: {100*grid_search.best_estimator_.oob_score_:.4f} %')\n",
    "print(f'Best validation accuracy: {100*grid_search.best_estimator_.score(X_val, y_val):.4f} %')\n",
    "print(f'Best test accuracy: {100*grid_search.best_estimator_.score(X_test, y_test):.4f} %')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
