{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(x_path, y_path):\n",
    "    '''\n",
    "    Args:\n",
    "        x_path: path to x file\n",
    "        y_path: path to y file\n",
    "    Returns:\n",
    "        x: np array of [NUM_OF_SAMPLES x n]\n",
    "        y: np array of [NUM_OF_SAMPLES]\n",
    "    '''\n",
    "    x = np.load(x_path)\n",
    "    y = np.load(y_path)\n",
    "\n",
    "    y = y.astype('float')\n",
    "    x = x.astype('float')\n",
    "\n",
    "    #normalize x:\n",
    "    x = 2*(0.5 - x/255)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = get_data('x_train.npy', 'y_train.npy')\n",
    "X_test, y_test = get_data('x_test.npy', 'y_test.npy')\n",
    "\n",
    "label_encoder = OneHotEncoder(sparse_output = False)\n",
    "label_encoder.fit(np.expand_dims(y_train, axis = -1))\n",
    "\n",
    "y_train_onehot = label_encoder.transform(np.expand_dims(y_train, axis = -1))\n",
    "y_test_onehot = label_encoder.transform(np.expand_dims(y_test, axis = -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self, M, n, hidden_arch, r, lr=0.01, lr_type=0, activation = 'sigmoid'):\n",
    "        '''\n",
    "        Args:\n",
    "            M: batch size\n",
    "            n: number of features\n",
    "            hidden_layer_architecture: list of number of perceptrons in each hidden layer\n",
    "            r: number of target classes\n",
    "            lr: learning rate\n",
    "            lr_type: 0 for constant learning rate, 1 for learning rate decay\n",
    "            activation: activation function to use in hidden layers ('sigmoid'/'relu'/'leaky_relu')\n",
    "        '''\n",
    "        self.M = M\n",
    "        self.n = n\n",
    "        self.hidden_arch = hidden_arch\n",
    "        self.r = r\n",
    "        self.lr = lr\n",
    "        self.lr_type = lr_type\n",
    "        self.activation = activation\n",
    "\n",
    "        #initialize weights and biases\n",
    "        self.weights = []\n",
    "        self.biases = []\n",
    "\n",
    "        if activation == 'relu' or activation == 'leaky_relu':\n",
    "            for i in range(len(hidden_arch)):\n",
    "                if i == 0:\n",
    "                    self.weights.append(np.random.normal(0, 1/np.sqrt(n), (n, hidden_arch[i])))\n",
    "                    self.biases.append(np.random.normal(0, 1/np.sqrt(n), (1, hidden_arch[i])))\n",
    "                else:\n",
    "                    self.weights.append(np.random.normal(0, 1/np.sqrt(hidden_arch[i-1]), (hidden_arch[i-1], hidden_arch[i])))\n",
    "                    self.biases.append(np.random.normal(0, 1/np.sqrt(hidden_arch[i-1]), (1, hidden_arch[i])))\n",
    "\n",
    "            self.weights.append(np.random.normal(0, 1/np.sqrt(hidden_arch[-1]), (hidden_arch[-1], r)))\n",
    "            self.biases.append(np.random.normal(0, 1/np.sqrt(hidden_arch[-1]), (1, r)))\n",
    "\n",
    "        else:\n",
    "            for i in range(len(hidden_arch)):\n",
    "                if i == 0:\n",
    "                    self.weights.append(np.random.normal(0, 1, (n, hidden_arch[i])))\n",
    "                    self.biases.append(np.random.normal(0, 1, (1, hidden_arch[i])))\n",
    "                else:\n",
    "                    self.weights.append(np.random.normal(0, 1, (hidden_arch[i-1], hidden_arch[i])))\n",
    "                    self.biases.append(np.random.normal(0, 1, (1, hidden_arch[i])))\n",
    "\n",
    "            self.weights.append(np.random.normal(0, 1, (hidden_arch[-1], r)))\n",
    "            self.biases.append(np.random.normal(0, 1, (1, r)))\n",
    "\n",
    "        #initialize activations and net values\n",
    "        self.activations = []\n",
    "        self.net = []\n",
    "        for i in range(len(hidden_arch)):\n",
    "            self.activations.append(np.zeros((M, hidden_arch[i])))\n",
    "            self.net.append(np.zeros((M, hidden_arch[i])))\n",
    "        self.activations.append(np.zeros((M, r)))\n",
    "        self.net.append(np.zeros((M, r)))\n",
    "\n",
    "        #initialize gradients (partial derivative of loss w.r.t weights)\n",
    "        self.gradients = []\n",
    "        for i in range(len(hidden_arch)):\n",
    "            self.gradients.append(np.zeros((M, hidden_arch[i])))\n",
    "        self.gradients.append(np.zeros((M, r)))\n",
    "\n",
    "        #initialize delta (partial derivative of loss w.r.t net values)\n",
    "        self.delta = []\n",
    "        for i in range(len(hidden_arch)):\n",
    "            self.delta.append(np.zeros((M, hidden_arch[i])))\n",
    "        self.delta.append(np.zeros((M, r)))\n",
    "\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "        return 1/(1 + np.exp(-x))\n",
    "    \n",
    "    def softmax(self, x):\n",
    "        # to avoid overflow\n",
    "        x -= np.max(x, axis = 1, keepdims = True)\n",
    "        return np.exp(x)/np.sum(np.exp(x), axis = 1, keepdims = True)\n",
    "    \n",
    "    def relu(self, x):\n",
    "        return np.maximum(0, x)\n",
    "    \n",
    "    def leaky_relu(self, x):\n",
    "        return np.maximum(1e-4*x, x)\n",
    "    \n",
    "\n",
    "    def forward(self, x:np.ndarray):\n",
    "        '''\n",
    "        Args:\n",
    "            x: np array of [M x n]\n",
    "        '''\n",
    "        #forward pass for hidden layers\n",
    "        for i in range(len(self.hidden_arch)):\n",
    "            if i == 0:\n",
    "                self.net[i] = x @ self.weights[i] + self.biases[i]\n",
    "            else:\n",
    "                self.net[i] = self.activations[i-1] @ self.weights[i] + self.biases[i]\n",
    "            if self.activation == 'sigmoid':\n",
    "                self.activations[i] = self.sigmoid(self.net[i])\n",
    "            elif self.activation == 'relu':\n",
    "                self.activations[i] = self.relu(self.net[i])\n",
    "            elif self.activation == 'leaky_relu':\n",
    "                self.activations[i] = self.leaky_relu(self.net[i])\n",
    "\n",
    "        #forward pass for output layer\n",
    "        self.net[-1] = self.activations[-2] @ self.weights[-1] + self.biases[-1]\n",
    "        self.activations[-1] = self.softmax(self.net[-1])\n",
    "\n",
    "\n",
    "    def backward(self, x:np.ndarray, y:np.ndarray):\n",
    "        '''\n",
    "        Args:\n",
    "            x: np array of [M x n]\n",
    "            y: np array of [M x r]\n",
    "        '''\n",
    "        #backward pass for output layer\n",
    "        self.delta[-1] = (self.activations[-1] - y)\n",
    "        self.gradients[-1] = (self.activations[-2].T @ self.delta[-1])\n",
    "\n",
    "        #backward pass for hidden layers\n",
    "        for i in range(len(self.hidden_arch)-1, 0, -1):\n",
    "            if self.activation == 'sigmoid':\n",
    "                self.delta[i] = (self.delta[i+1] @ self.weights[i+1].T) * self.activations[i] * (1 - self.activations[i])\n",
    "            elif self.activation == 'relu':\n",
    "                self.delta[i] = (self.delta[i+1] @ self.weights[i+1].T) * (self.net[i] > 0)\n",
    "            elif self.activation == 'leaky_relu':\n",
    "                self.delta[i] = (self.delta[i+1] @ self.weights[i+1].T) * (self.net[i] > 0) + 0.01*(self.delta[i+1] @ self.weights[i+1].T) * (self.net[i] < 0)\n",
    "            self.gradients[i] = self.activations[i-1].T @ self.delta[i]\n",
    "\n",
    "        #backward pass for first hidden layer\n",
    "        if self.activation == 'sigmoid':\n",
    "            self.delta[0] = (self.delta[1] @ self.weights[1].T) * self.activations[0] * (1 - self.activations[0])\n",
    "        elif self.activation == 'relu':\n",
    "            self.delta[0] = (self.delta[1] @ self.weights[1].T) * (self.net[0] > 0)\n",
    "        elif self.activation == 'leaky_relu':\n",
    "            self.delta[0] = (self.delta[1] @ self.weights[1].T) * (self.net[0] > 0) + 0.01*(self.delta[1] @ self.weights[1].T) * (self.net[0] < 0)\n",
    "        self.gradients[0] = x.T @ self.delta[0]\n",
    "\n",
    "\n",
    "    def update(self, epoch=1):\n",
    "        '''\n",
    "        Args:\n",
    "            epoch: current epoch number (1-indexed)\n",
    "        '''\n",
    "        if self.lr_type == 0:\n",
    "            epoch = 1\n",
    "        for i in range(len(self.weights)):\n",
    "            self.weights[i] -= self.lr/np.sqrt(epoch) * self.gradients[i]\n",
    "            self.biases[i] -= self.lr/np.sqrt(epoch) * np.sum(self.delta[i], axis = 0, keepdims = True)\n",
    "\n",
    "\n",
    "    def fit(self, X_train:np.ndarray, y_train:np.ndarray, max_epochs = 1000, tol = 0, verbose = True):\n",
    "        '''\n",
    "        Args:\n",
    "            X_train: np array of [NUM_OF_SAMPLES x n]\n",
    "            y_train: np array of [NUM_OF_SAMPLES]\n",
    "            max_epochs: maximum number of epochs to train\n",
    "            tol: tolerance for convergence\n",
    "        '''\n",
    "        self.loss = []\n",
    "        m = X_train.shape[0]\n",
    "        y_train_onehot = label_encoder.transform(np.expand_dims(y_train, axis = -1))\n",
    "\n",
    "        rng = range(max_epochs)\n",
    "        if verbose:\n",
    "            rng= tqdm(rng)\n",
    "        for epoch in rng:\n",
    "            perm = np.random.permutation(m)\n",
    "            X_train = X_train[perm]\n",
    "            y_train_onehot = y_train_onehot[perm]\n",
    "\n",
    "            for i in range(0, m, self.M):\n",
    "                x = X_train[i:i+self.M]\n",
    "                y = y_train_onehot[i:i+self.M]\n",
    "\n",
    "                self.forward(x)\n",
    "                self.backward(x, y)\n",
    "                self.update(epoch+1)\n",
    "\n",
    "            if tol>0:\n",
    "                self.forward(X_train)\n",
    "                loss = -np.sum(y_train_onehot * np.log(self.activations[-1]))/self.M\n",
    "                self.loss.append(loss)\n",
    "                if epoch > 0 and abs(self.loss[-1] - self.loss[-2]) < tol:\n",
    "                    break\n",
    "\n",
    "\n",
    "    def predict(self, X_test:np.ndarray):\n",
    "        '''\n",
    "        Args:\n",
    "            X_test: np array of [NUM_OF_TEST_SAMPLES x n]\n",
    "        '''\n",
    "        self.forward(X_test)\n",
    "        return 1+np.argmax(self.activations[-1], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_archs = [[1], [5], [10], [50], [100]]\n",
    "precision_scores_train = []\n",
    "precision_scores_test = []\n",
    "recall_scores_train = []\n",
    "recall_scores_test = []\n",
    "f1_scores_train = []\n",
    "f1_scores_test = []\n",
    "for hidden_arch in hidden_archs:\n",
    "    nn = NeuralNetwork(M = 32, n = 1024, hidden_arch = hidden_arch, r = 5, lr = 0.01)\n",
    "    nn.fit(X_train, y_train, max_epochs = 1000, tol = 5e-3)\n",
    "    y_pred_train = nn.predict(X_train)\n",
    "    cr_train = classification_report(y_pred_train, y_train, output_dict = True, zero_division=0)\n",
    "    precision_scores_train.append(cr_train['macro avg']['precision'])\n",
    "    # print(cr_train['macro avg']['precision'])\n",
    "    recall_scores_train.append(cr_train['macro avg']['recall'])\n",
    "    f1_scores_train.append(cr_train['macro avg']['f1-score'])\n",
    "    y_pred_test = nn.predict(X_test)\n",
    "    cr_test = classification_report(y_pred_test, y_test, output_dict = True, zero_division=0)\n",
    "    precision_scores_test.append(cr_test['macro avg']['precision'])\n",
    "    recall_scores_test.append(cr_test['macro avg']['recall'])\n",
    "    f1_scores_test.append(cr_test['macro avg']['f1-score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'Hidden Layer Architecture': hidden_archs,\n",
    "    'Train Precision': precision_scores_train,\n",
    "    'Test Precision': precision_scores_test,\n",
    "    'Train Recall': recall_scores_train,\n",
    "    'Test Recall': recall_scores_test,\n",
    "    'Train F1': f1_scores_train,\n",
    "    'Test F1': f1_scores_test\n",
    "}).round(4)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "units = [x[0] for x in hidden_archs]\n",
    "plt.clf()\n",
    "plt.plot(units, f1_scores_train, label = 'Train')\n",
    "plt.plot(units, f1_scores_test, label = 'Test')\n",
    "plt.scatter(units, f1_scores_train)\n",
    "plt.scatter(units, f1_scores_test)\n",
    "plt.xlabel('Number of Hidden Units')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.xscale('log')\n",
    "plt.legend()\n",
    "plt.title('Q2(b): F1 Score vs Number of Hidden Layer Units')\n",
    "plt.savefig('plots/q2b_f1.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_archs = [[512], [512, 256], [512, 256, 128], [512, 256, 128, 64]]\n",
    "hidden_depths = [1, 2, 3, 4]\n",
    "precision_scores_train = []\n",
    "precision_scores_test = []\n",
    "recall_scores_train = []\n",
    "recall_scores_test = []\n",
    "f1_scores_train = []\n",
    "f1_scores_test = []\n",
    "\n",
    "for hidden_arch in hidden_archs:\n",
    "    nn = NeuralNetwork(M = 32, n = 1024, hidden_arch = hidden_arch, r = 5, lr = 0.01)\n",
    "    nn.fit(X_train, y_train, max_epochs = 200, tol = 1e-3)\n",
    "    y_pred_train = nn.predict(X_train)\n",
    "    cr_train = classification_report(y_pred_train, y_train, output_dict = True, zero_division=0)\n",
    "    precision_scores_train.append(cr_train['macro avg']['precision'])\n",
    "    recall_scores_train.append(cr_train['macro avg']['recall'])\n",
    "    f1_scores_train.append(cr_train['macro avg']['f1-score'])\n",
    "    y_pred_test = nn.predict(X_test)\n",
    "    cr_test = classification_report(y_pred_test, y_test, output_dict = True, zero_division=0)\n",
    "    precision_scores_test.append(cr_test['macro avg']['precision'])\n",
    "    recall_scores_test.append(cr_test['macro avg']['recall'])\n",
    "    f1_scores_test.append(cr_test['macro avg']['f1-score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'Hidden Layer Architecture': hidden_archs,\n",
    "    'Train Precision': precision_scores_train,\n",
    "    'Test Precision': precision_scores_test,\n",
    "    'Train Recall': recall_scores_train,\n",
    "    'Test Recall': recall_scores_test,\n",
    "    'Train F1': f1_scores_train,\n",
    "    'Test F1': f1_scores_test\n",
    "}).round(4)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "plt.plot(hidden_depths, f1_scores_train, label = 'Train')\n",
    "plt.plot(hidden_depths, f1_scores_test, label = 'Test')\n",
    "plt.scatter(hidden_depths, f1_scores_train)\n",
    "plt.scatter(hidden_depths, f1_scores_test)\n",
    "plt.xlabel('Network Depth')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.legend()\n",
    "plt.title('Q2(c): F1 Score vs Network Depth')\n",
    "plt.savefig('plots/q2c_f1.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_archs = [[512], [512, 256], [512, 256, 128], [512, 256, 128, 64]]\n",
    "hidden_depths = [1, 2, 3, 4]\n",
    "precision_scores_train = []\n",
    "precision_scores_test = []\n",
    "recall_scores_train = []\n",
    "recall_scores_test = []\n",
    "f1_scores_train = []\n",
    "f1_scores_test = []\n",
    "\n",
    "for hidden_arch in hidden_archs:\n",
    "    nn = NeuralNetwork(M = 32, n = 1024, hidden_arch = hidden_arch, r = 5, lr = 0.01, lr_type = 1)\n",
    "    nn.fit(X_train, y_train, max_epochs = 200, tol = 1e-4)\n",
    "    y_pred_train = nn.predict(X_train)\n",
    "    cr_train = classification_report(y_pred_train, y_train, output_dict = True, zero_division=0)\n",
    "    precision_scores_train.append(cr_train['macro avg']['precision'])\n",
    "    recall_scores_train.append(cr_train['macro avg']['recall'])\n",
    "    f1_scores_train.append(cr_train['macro avg']['f1-score'])\n",
    "    y_pred_test = nn.predict(X_test)\n",
    "    cr_test = classification_report(y_pred_test, y_test, output_dict = True, zero_division=0)\n",
    "    precision_scores_test.append(cr_test['macro avg']['precision'])\n",
    "    recall_scores_test.append(cr_test['macro avg']['recall'])\n",
    "    f1_scores_test.append(cr_test['macro avg']['f1-score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'Hidden Layer Architecture': hidden_archs,\n",
    "    'Train Precision': precision_scores_train,\n",
    "    'Test Precision': precision_scores_test,\n",
    "    'Train Recall': recall_scores_train,\n",
    "    'Test Recall': recall_scores_test,\n",
    "    'Train F1': f1_scores_train,\n",
    "    'Test F1': f1_scores_test\n",
    "}).round(4)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "plt.plot(hidden_depths, f1_scores_train, label = 'Train')\n",
    "plt.plot(hidden_depths, f1_scores_test, label = 'Test')\n",
    "plt.scatter(hidden_depths, f1_scores_train)\n",
    "plt.scatter(hidden_depths, f1_scores_test)\n",
    "plt.xlabel('Network Depth')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.legend()\n",
    "plt.title('Q2(d): F1 Score vs Network Depth')\n",
    "plt.savefig('plots/q2d_f1.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_archs = [[512], [512, 256], [512, 256, 128], [512, 256, 128, 64]]\n",
    "hidden_depths = [1, 2, 3, 4]\n",
    "precision_scores_train = []\n",
    "precision_scores_test = []\n",
    "recall_scores_train = []\n",
    "recall_scores_test = []\n",
    "f1_scores_train = []\n",
    "f1_scores_test = []\n",
    "\n",
    "for hidden_arch in hidden_archs:\n",
    "    nn = NeuralNetwork(M = 32, n = 1024, hidden_arch = hidden_arch, r = 5, lr = 0.01, lr_type = 1, activation = 'leaky_relu')\n",
    "    nn.fit(X_train, y_train, max_epochs = 100, tol = 0)\n",
    "    y_pred_train = nn.predict(X_train)\n",
    "    cr_train = classification_report(y_pred_train, y_train, output_dict = True, zero_division=0)\n",
    "    precision_scores_train.append(cr_train['macro avg']['precision'])\n",
    "    recall_scores_train.append(cr_train['macro avg']['recall'])\n",
    "    f1_scores_train.append(cr_train['macro avg']['f1-score'])\n",
    "    print(cr_train['macro avg']['f1-score'])\n",
    "    y_pred_test = nn.predict(X_test)\n",
    "    cr_test = classification_report(y_pred_test, y_test, output_dict = True, zero_division=0)\n",
    "    precision_scores_test.append(cr_test['macro avg']['precision'])\n",
    "    recall_scores_test.append(cr_test['macro avg']['recall'])\n",
    "    f1_scores_test.append(cr_test['macro avg']['f1-score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'Hidden Layer Architecture': hidden_archs,\n",
    "    'Train Precision': precision_scores_train,\n",
    "    'Test Precision': precision_scores_test,\n",
    "    'Train Recall': recall_scores_train,\n",
    "    'Test Recall': recall_scores_test,\n",
    "    'Train F1': f1_scores_train,\n",
    "    'Test F1': f1_scores_test\n",
    "}).round(4)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "plt.plot(hidden_depths, f1_scores_train, label = 'Train')\n",
    "plt.plot(hidden_depths, f1_scores_test, label = 'Test')\n",
    "plt.scatter(hidden_depths, f1_scores_train)\n",
    "plt.scatter(hidden_depths, f1_scores_test)\n",
    "plt.xlabel('Network Depth')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.legend()\n",
    "plt.title('Q2(e): F1 Score vs Network Depth')\n",
    "plt.savefig('plots/q2e_f1.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_archs = [[512], [512, 256], [512, 256, 128], [512, 256, 128, 64]]\n",
    "hidden_depths = [1, 2, 3, 4]\n",
    "precision_scores_train = []\n",
    "precision_scores_test = []\n",
    "recall_scores_train = []\n",
    "recall_scores_test = []\n",
    "f1_scores_train = []\n",
    "f1_scores_test = []\n",
    "\n",
    "for hidden_arch in hidden_archs:\n",
    "    nn = MLPClassifier(hidden_layer_sizes=hidden_arch, activation='relu', solver='sgd', alpha=0, batch_size=32, learning_rate='invscaling')\n",
    "    nn.fit(X_train, y_train)\n",
    "    y_pred_train = nn.predict(X_train)\n",
    "    cr_train = classification_report(y_pred_train, y_train, output_dict = True, zero_division=0)\n",
    "    precision_scores_train.append(cr_train['macro avg']['precision'])\n",
    "    recall_scores_train.append(cr_train['macro avg']['recall'])\n",
    "    f1_scores_train.append(cr_train['macro avg']['f1-score'])\n",
    "    y_pred_test = nn.predict(X_test)\n",
    "    cr_test = classification_report(y_pred_test, y_test, output_dict = True, zero_division=0)\n",
    "    precision_scores_test.append(cr_test['macro avg']['precision'])\n",
    "    recall_scores_test.append(cr_test['macro avg']['recall'])\n",
    "    f1_scores_test.append(cr_test['macro avg']['f1-score'])\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'Hidden Layer Architecture': hidden_archs,\n",
    "    'Train Precision': precision_scores_train,\n",
    "    'Test Precision': precision_scores_test,\n",
    "    'Train Recall': recall_scores_train,\n",
    "    'Test Recall': recall_scores_test,\n",
    "    'Train F1': f1_scores_train,\n",
    "    'Test F1': f1_scores_test\n",
    "}).round(4)\n",
    "display(df)\n",
    "\n",
    "plt.clf()\n",
    "plt.plot(hidden_depths, f1_scores_train, label = 'Train')\n",
    "plt.plot(hidden_depths, f1_scores_test, label = 'Test')\n",
    "plt.scatter(hidden_depths, f1_scores_train)\n",
    "plt.scatter(hidden_depths, f1_scores_test)\n",
    "plt.xlabel('Network Depth')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.legend()\n",
    "plt.title('Q2(f): F1 Score vs Network Depth')\n",
    "plt.savefig('plots/q2f_f1.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
